services:
  llm-api:
    build: .
    ports:
      - "8080:8080"
    volumes:
      - ~/.cache/gpt4all:/root/.cache/gpt4all
    environment:
      - MODEL_NAME=Meta-Llama-3-8B-Instruct.Q4_0.gguf
